---
title: "A2 - RegresiÃ³n MÃºltiple"
author: "HÃ©ctor Hibran Tapia FernÃ¡ndez - A01661114"
date: "2024-09-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Haz un anÃ¡lisis descriptivo de los datos: medidas principales y grÃ¡ficos

```{r}
df = read.csv("./AlCorte.csv")
summary(df)
```

```{r}
hist(df$Fuerza, main = "Histograma de Fuerza", xlab = "Fuerza", col = "lightblue")
hist(df$Potencia, main = "Histograma de Potencia", xlab = "Potencia", col = "lightgreen")
hist(df$Temperatura, main = "Histograma de Temperatura", xlab = "Temperatura", col = "lightcoral")
hist(df$Tiempo, main = "Histograma de Tiempo", xlab = "Tiempo", col = "lightyellow")
hist(df$Resistencia, main = "Histograma de Resistencia", xlab = "Resistencia", col = "lightpink")
```

```{r}
boxplot(df$Fuerza, main = "Boxplot de Fuerza", col = "lightblue", ylab = "Fuerza")
boxplot(df$Potencia, main = "Boxplot de Potencia", col = "lightgreen", ylab = "Potencia")
boxplot(df$Temperatura, main = "Boxplot de Temperatura", col = "lightcoral", ylab = "Temperatura")
boxplot(df$Tiempo, main = "Boxplot de Tiempo", col = "lightyellow", ylab = "Tiempo")
boxplot(df$Resistencia, main = "Boxplot de Resistencia", col = "lightpink", ylab = "Resistencia")
```
```{r}
pairs(df, main = "Scatter plots entre todas las variables", col = "blue", pch = 19)
```

## 2. Encuentra el mejor modelo de regresiÃ³n que explique la variable Resistencia. 

```{r}
modelo_completo = lm(Resistencia ~ ., data = df)
modelo_nulo = lm(Resistencia ~ 1, data = df)

# Modelo Mixto
modelo_mixto = step(modelo_completo, direction = "both", trace = 1)
```

```{r}
# Modelo Forward
modelo_forward = step(modelo_nulo, scope = list(lower = modelo_nulo, upper = modelo_completo), direction = "forward")
```

```{r}
# Modelo Backward
modelo_backward = step(modelo_completo, direction = "backward")
```

## Analiza el modelo basÃ¡ndote en:

### - Significancia del modelo:
### 1. EconomÃ­a de las variables
    
```{r}
summary(modelo_mixto)
cat("------------------------------------------------------------------")
summary(modelo_forward)
cat("------------------------------------------------------------------")
summary(modelo_backward)
```


### 2. SignificaciÃ³n global (Prueba para el modelo)
    
```{r}
summary(modelo_mixto)$fstatistic
print("--------------------------")
summary(modelo_forward)$fstatistic
print("--------------------------")
summary(modelo_backward)$fstatistic
```

### 3. SignificaciÃ³n individual (Prueba para cada ð›½ð‘–)

```{r}
summary(modelo_mixto)$coefficients
confint(modelo_mixto)
print("----------------------------------------------------------")
summary(modelo_forward)$coefficients
confint(modelo_forward)
print("----------------------------------------------------------")
summary(modelo_backward)$coefficients
confint(modelo_backward)
```

### 4. VariaciÃ³n explicada por el modelo

```{r}
summary(modelo_mixto)$r.squared
summary(modelo_mixto)$adj.r.squared
print("----------")
summary(modelo_forward)$r.squared
summary(modelo_forward)$adj.r.squared
print("----------")
summary(modelo_backward)$r.squared
summary(modelo_backward)$adj.r.squared
```
    
## 3. Analiza la validez del modelo encontrado:

### - AnÃ¡lisis de residuos (homocedasticidad, independencia, etc)

```{r}
library(nortest)

ad.test(modelo_mixto$residuals)
qqnorm(modelo_mixto$residuals, main = "GrÃ¡fico Q-Q de los Residuos")
qqline(modelo_mixto$residuals, col = "red")

hist(modelo_mixto$residuals, freq = FALSE, ylim = c(0, 0.15), main = "Histograma de los Residuos", xlab = "Residuos")
lines(density(modelo_mixto$residuals), col = "red")
curve(dnorm(x, mean = mean(modelo_mixto$residuals), sd = sd(modelo_mixto$residuals)), from = -6, to = 6, add = TRUE, col = "blue", lwd = 2)
```


```{r}
plot(predict(modelo_forward), residuals(modelo_forward), main = "Residuos vs Valores Ajustados", xlab = "Valores Ajustados", ylab = "Residuos", pch = 19, col = "blue")
abline(h = 0, col = "red")
```

```{r}
library(lmtest) 
# Homocedasticidad
bptest(modelo_mixto)  # Prueba de Breusch-Pagan
```
```{r}
# Independencia
dwtest(modelo_mixto)  # Prueba de Durbin-Watson
bgtest(modelo_mixto) # Prueba de Breusch-Godfrey
```
```{r}
# Linealidad
resettest(modelo_mixto) # Prueba de RESET de Ramsey
```

### - No multicolinealidad de X_i

```{r}
library(car)
vif(modelo_mixto)  
cor(df[, c("Potencia", "Temperatura")])
```

## 4. Emite conclusiones sobre el modelo final encontrado e interpreta en el contexto del problema el efecto de las variables predictoras en la variable respuesta.

En general se realizÃ³ un anÃ¡lisis para validar cual de los tres modelos (mixto, forward, backward) es mejor.
Y cuÃ¡l de estos predice la variable dependiente "Resistencia", como se mostrÃ³ despuÃ©s de aplicar cada modelo, los tres llegaron a la misma conclusiÃ³n que el mejor modelo es "Resistencia ~ Potencia + Temperatura", por supuesto cada modelo tuvo su forma especifica de como es que llegaron a esta conclusiÃ³n. Esto nos indica que estas dos variables predictoras (Potencia ,Temperatura) son las mejores para ayudar a predecir Resistencia, ya que estas resultaron ser las mÃ¡s significativas para explicar la variabilidad de Resistencia.

Ahora al evaluar la **homocedasticidad** usando la prueba de Breusch-Pagan, tenemos las siguientes hipÃ³tesis:

- HipÃ³tesis nula (Hâ‚€): Los residuos del modelo son homocedÃ¡sticos (la varianza de los residuos es constante a lo largo de todas las observaciones).
- HipÃ³tesis alternativa (Hâ‚): Los residuos presentan heterocedasticidad (la varianza de los residuos no es constante).

Dado que en nuestro caso el p-valor = 0.135 es mayor que 0.05, deducimos que no hay suficiente evidencia para rechazar la hipÃ³tesis nula de homocedasticidad. Lo que significa que no se detecta heterocedasticidad en los residuos del modelo, por lo que se puede asumir que la varianza de los errores es constante.

El modelo cumple con el supuesto de homocedasticidad, lo que es una bueno. La prueba no encontrÃ³ ninguna evidencia de que la varianza de los residuos cambie a lo largo de los valores predichos, lo cual valida aÃºn mÃ¡s el modelo.

Ahora para la **independecia** se realizaron las siguientes pruebas:

- Prueba de Durbin-Watson
- Prueba de Breusch-Godfrey

EstÃ¡s pruebas nos ayudan a detectar la autocorrelaciÃ³n de los residuos en un modelo de regresiÃ³n, lo que buscamos es que no haya autocorrelaciÃ³n en nuestros residuos.

Y eso mismo nos dicen ambas pruebas, en la prueba de Durbin-Watson, el estadÃ­stico DW = 2.35 y el p-valor = 0.8267 nos dicen que los residuos no tienen autocorrelaciÃ³n significativa, ya que un valor cercano a 2 indica independencia de los errores.(Puede variar entre 0 y 4, 2 seria el neutro en este caso) Igual, de manera similar, la prueba de Breusch-Godfrey tambiÃ©n mostrÃ³ un p-valor = 0.2863, lo que confirma que no hay autocorrelaciÃ³n de orden superior en los residuos. Con ambos resultados, podemos validar el supuesto de independencia de los errores en el modelo.

Ahora explicando la **linealidad**:

Se realizÃ³ la prueba de RESET de Ramsey, lo que nos muestra un p-valor = 0.4647, esto nos dice que no hay suficiente evidencia para rechazar la hipÃ³tesis nula de que el modelo estÃ¡ correctamente especificado. Esto significa que la relaciÃ³n entre las variables predictoras y la variable dependiente es lineal, y no es necesario agregar tÃ©rminos no lineales (como cuadrÃ¡ticos o cÃºbicos) para mejorar el ajuste del modelo.

**VIF y Matriz de correlaciÃ³n**

El VIF mide cuÃ¡nto la varianza de un coeficiente de regresiÃ³n estÃ¡ "inflada" debido a la colinealidad con otras variables predictoras. Un VIF = 1 significa que no hay correlaciÃ³n entre una variable y las demÃ¡s.

En nuestro casol os resultados que nos da para VIF muestran que tanto Potencia como Temperatura tienen un VIF = 1. Esto es lo mejor que se puede obtener, ya que significa que no existe ninguna colinealidad entre las variables.

Con esto, podemos tener una pequeÃ±a idea de como se verÃ­a la matriz de correlaciÃ³n.

CorrelaciÃ³n 0 entre Potencia y Temperatura significa que no hay relaciÃ³n lineal entre estas variables. Esto confirma que no hay problemas de multicolinealidad.

**Y con esto hemos concluido que el mejor modelo es "Resistencia ~ Potencia + Temperatura", donde se observa que solo necesitamos de dos variables, lo cual hace el modelo simple, pero efectivo.**


# AnÃ¡lisis de Datos AtÃ­picos

A continuaciÃ³n realizaremos un anÃ¡lisis detallado de los datos atÃ­picos e incluyentes del mejor modelo encontrado.

```{r}
modelo_mixto
```

```{r}
hatvalues(modelo_mixto)
```

```{r}
rstudent(modelo_mixto)
```

```{r}
cooks.distance(modelo_mixto)
```
```{r}
 I = influence.measures(modelo_mixto)
summary (I)
```

```{r}
dfbetas(modelo_mixto)
```

## EstandarizaciÃ³n Extrema de los Residuos

```{r}
df$residuos_estandarizados = rstudent(modelo_mixto)
df$cooksd = cooks.distance(modelo_mixto)

df$outlier = ifelse(abs(df$residuos_estandarizados) > 3, TRUE, FALSE)
df$influyente = ifelse(df$cooksd > 4 / nrow(df), TRUE, FALSE)

df_atipicos_influyentes <- df[df$outlier | df$influyente, ]

library(ggplot2)

ggplot(data = df, aes(x = predict(modelo_mixto), y = abs(residuos_estandarizados))) +
  geom_point(aes(color = outlier, shape = influyente), size = 3) +
  geom_hline(yintercept = 3, linetype = "dashed", color = "blue") +  # Umbral de residuos atÃ­picos
  geom_hline(yintercept = -3, linetype = "dashed", color = "blue") +
  scale_color_manual(values = c('black', 'red')) +
  scale_shape_manual(values = c(16, 17)) +  
  labs(title = "DistribuciÃ³n de residuos estandarizados y puntos influyentes",
       x = "PredicciÃ³n del modelo",
       y = "Residuos estandarizados absolutos",
       color = "AtÃ­pico",
       shape = "Influyente") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_text(data = df_atipicos_influyentes, 
            aes(x = predict(modelo_mixto)[df$outlier | df$influyente], 
                y = abs(residuos_estandarizados)[df$outlier | df$influyente],
                label = rownames(df_atipicos_influyentes)), 
            vjust = -1, color = "darkred")
```


## Distancia de Leverange (diagonal de la matriz sombrero)

```{r}
leverage = hatvalues(modelo_mixto)
plot(leverage, type="h", main="Valores de Apalancamiento", ylab="Apalancamiento")
abline(h = 2*mean(leverage), col="red") 
```

```{r}
high_leverage_points = which(leverage > 2*mean(leverage))
high_leverage_points
```


## Distancia de Cook

```{r}
cooksdistance <- cooks.distance(modelo_mixto)

plot(cooksdistance, type="h", main="Distancia de Cook", ylab="Distancia de Cook")
abline(h = 1, col="red") 
```

## DfBetas

```{r}
dfbetas_values = dfbetas(modelo_mixto)

plot(dfbetas_values[, 2], type="h", main='DfBetas',
ylab="DfBetas")
abline(h = c(-1, 1), col="red")
```


## Datos Influyentes

```{r}
influencia = influence.measures(modelo_mixto)
summary(influencia)
```

```{r}
library(car)
influencePlot(modelo_mixto)
```

```{r}
par(mfrow=c(2, 2))
plot(modelo_mixto, col = 'blue', pch = 19)
```

