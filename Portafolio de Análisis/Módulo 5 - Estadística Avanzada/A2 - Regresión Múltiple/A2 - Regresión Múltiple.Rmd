---
title: "A2 - Regresi√≥n M√∫ltiple"
author: "H√©ctor Hibran Tapia Fern√°ndez - A01661114"
date: "2024-09-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Haz un an√°lisis descriptivo de los datos: medidas principales y gr√°ficos

```{r}
df = read.csv("./AlCorte.csv")
summary(df)
```

```{r}
hist(df$Fuerza, main = "Histograma de Fuerza", xlab = "Fuerza", col = "lightblue")
hist(df$Potencia, main = "Histograma de Potencia", xlab = "Potencia", col = "lightgreen")
hist(df$Temperatura, main = "Histograma de Temperatura", xlab = "Temperatura", col = "lightcoral")
hist(df$Tiempo, main = "Histograma de Tiempo", xlab = "Tiempo", col = "lightyellow")
hist(df$Resistencia, main = "Histograma de Resistencia", xlab = "Resistencia", col = "lightpink")
```

```{r}
boxplot(df$Fuerza, main = "Boxplot de Fuerza", col = "lightblue", ylab = "Fuerza")
boxplot(df$Potencia, main = "Boxplot de Potencia", col = "lightgreen", ylab = "Potencia")
boxplot(df$Temperatura, main = "Boxplot de Temperatura", col = "lightcoral", ylab = "Temperatura")
boxplot(df$Tiempo, main = "Boxplot de Tiempo", col = "lightyellow", ylab = "Tiempo")
boxplot(df$Resistencia, main = "Boxplot de Resistencia", col = "lightpink", ylab = "Resistencia")
```
```{r}
pairs(df, main = "Scatter plots entre todas las variables", col = "blue", pch = 19)
```

## 2. Encuentra el mejor modelo de regresi√≥n que explique la variable Resistencia. 

```{r}
modelo_completo = lm(Resistencia ~ ., data = df)
modelo_nulo = lm(Resistencia ~ 1, data = df)

# Modelo Mixto
modelo_mixto = step(modelo_completo, direction = "both", trace = 1)
```

```{r}
# Modelo Forward
modelo_forward = step(modelo_nulo, scope = list(lower = modelo_nulo, upper = modelo_completo), direction = "forward")
```

```{r}
# Modelo Backward
modelo_backward = step(modelo_completo, direction = "backward")
```

## Analiza el modelo bas√°ndote en:

### - Significancia del modelo:
### 1. Econom√≠a de las variables
    
```{r}
summary(modelo_mixto)
cat("------------------------------------------------------------------")
summary(modelo_forward)
cat("------------------------------------------------------------------")
summary(modelo_backward)
```


### 2. Significaci√≥n global (Prueba para el modelo)
    
```{r}
summary(modelo_mixto)$fstatistic
print("--------------------------")
summary(modelo_forward)$fstatistic
print("--------------------------")
summary(modelo_backward)$fstatistic
```

### 3. Significaci√≥n individual (Prueba para cada ùõΩùëñ)

```{r}
summary(modelo_mixto)$coefficients
confint(modelo_mixto)
print("----------------------------------------------------------")
summary(modelo_forward)$coefficients
confint(modelo_forward)
print("----------------------------------------------------------")
summary(modelo_backward)$coefficients
confint(modelo_backward)
```

### 4. Variaci√≥n explicada por el modelo

```{r}
summary(modelo_mixto)$r.squared
summary(modelo_mixto)$adj.r.squared
print("----------")
summary(modelo_forward)$r.squared
summary(modelo_forward)$adj.r.squared
print("----------")
summary(modelo_backward)$r.squared
summary(modelo_backward)$adj.r.squared
```
    
## 3. Analiza la validez del modelo encontrado:

### - An√°lisis de residuos (homocedasticidad, independencia, etc)

```{r}
library(nortest)

ad.test(modelo_mixto$residuals)
qqnorm(modelo_mixto$residuals, main = "Gr√°fico Q-Q de los Residuos")
qqline(modelo_mixto$residuals, col = "red")

hist(modelo_mixto$residuals, freq = FALSE, ylim = c(0, 0.15), main = "Histograma de los Residuos", xlab = "Residuos")
lines(density(modelo_mixto$residuals), col = "red")
curve(dnorm(x, mean = mean(modelo_mixto$residuals), sd = sd(modelo_mixto$residuals)), from = -6, to = 6, add = TRUE, col = "blue", lwd = 2)
```


```{r}
plot(predict(modelo_forward), residuals(modelo_forward), main = "Residuos vs Valores Ajustados", xlab = "Valores Ajustados", ylab = "Residuos", pch = 19, col = "blue")
abline(h = 0, col = "red")
```

```{r}
library(lmtest) 
# Homocedasticidad
bptest(modelo_mixto)  # Prueba de Breusch-Pagan
```
```{r}
# Independencia
dwtest(modelo_mixto)  # Prueba de Durbin-Watson
bgtest(modelo_mixto) # Prueba de Breusch-Godfrey
```
```{r}
# Linealidad
resettest(modelo_mixto) # Prueba de RESET de Ramsey
```

### - No multicolinealidad de X_i

```{r}
library(car)
vif(modelo_mixto)  
cor(df[, c("Potencia", "Temperatura")])
```

## 4. Emite conclusiones sobre el modelo final encontrado e interpreta en el contexto del problema el efecto de las variables predictoras en la variable respuesta.

En general se realiz√≥ un an√°lisis para validar cual de los tres modelos (mixto, forward, backward) es mejor.
Y cu√°l de estos predice la variable dependiente "Resistencia", como se mostr√≥ despu√©s de aplicar cada modelo, los tres llegaron a la misma conclusi√≥n que el mejor modelo es "Resistencia ~ Potencia + Temperatura", por supuesto cada modelo tuvo su forma especifica de como es que llegaron a esta conclusi√≥n. Esto nos indica que estas dos variables predictoras (Potencia ,Temperatura) son las mejores para ayudar a predecir Resistencia, ya que estas resultaron ser las m√°s significativas para explicar la variabilidad de Resistencia.

Ahora al evaluar la **homocedasticidad** usando la prueba de Breusch-Pagan, tenemos las siguientes hip√≥tesis:

- Hip√≥tesis nula (H‚ÇÄ): Los residuos del modelo son homoced√°sticos (la varianza de los residuos es constante a lo largo de todas las observaciones).
- Hip√≥tesis alternativa (H‚ÇÅ): Los residuos presentan heterocedasticidad (la varianza de los residuos no es constante).

Dado que en nuestro caso el p-valor = 0.135 es mayor que 0.05, deducimos que no hay suficiente evidencia para rechazar la hip√≥tesis nula de homocedasticidad. Lo que significa que no se detecta heterocedasticidad en los residuos del modelo, por lo que se puede asumir que la varianza de los errores es constante.

El modelo cumple con el supuesto de homocedasticidad, lo que es una bueno. La prueba no encontr√≥ ninguna evidencia de que la varianza de los residuos cambie a lo largo de los valores predichos, lo cual valida a√∫n m√°s el modelo.

Ahora para la **independecia** se realizaron las siguientes pruebas:

- Prueba de Durbin-Watson
- Prueba de Breusch-Godfrey

Est√°s pruebas nos ayudan a detectar la autocorrelaci√≥n de los residuos en un modelo de regresi√≥n, lo que buscamos es que no haya autocorrelaci√≥n en nuestros residuos.

Y eso mismo nos dicen ambas pruebas, en la prueba de Durbin-Watson, el estad√≠stico DW = 2.35 y el p-valor = 0.8267 nos dicen que los residuos no tienen autocorrelaci√≥n significativa, ya que un valor cercano a 2 indica independencia de los errores.(Puede variar entre 0 y 4, 2 seria el neutro en este caso) Igual, de manera similar, la prueba de Breusch-Godfrey tambi√©n mostr√≥ un p-valor = 0.2863, lo que confirma que no hay autocorrelaci√≥n de orden superior en los residuos. Con ambos resultados, podemos validar el supuesto de independencia de los errores en el modelo.

Ahora explicando la **linealidad**:

Se realiz√≥ la prueba de RESET de Ramsey, lo que nos muestra un p-valor = 0.4647, esto nos dice que no hay suficiente evidencia para rechazar la hip√≥tesis nula de que el modelo est√° correctamente especificado. Esto significa que la relaci√≥n entre las variables predictoras y la variable dependiente es lineal, y no es necesario agregar t√©rminos no lineales (como cuadr√°ticos o c√∫bicos) para mejorar el ajuste del modelo.

**VIF y Matriz de correlaci√≥n**

El VIF mide cu√°nto la varianza de un coeficiente de regresi√≥n est√° "inflada" debido a la colinealidad con otras variables predictoras. Un VIF = 1 significa que no hay correlaci√≥n entre una variable y las dem√°s.

En nuestro casol os resultados que nos da para VIF muestran que tanto Potencia como Temperatura tienen un VIF = 1. Esto es lo mejor que se puede obtener, ya que significa que no existe ninguna colinealidad entre las variables.

Con esto, podemos tener una peque√±a idea de como se ver√≠a la matriz de correlaci√≥n.

Correlaci√≥n 0 entre Potencia y Temperatura significa que no hay relaci√≥n lineal entre estas variables. Esto confirma que no hay problemas de multicolinealidad.

**Y con esto hemos concluido que el mejor modelo es "Resistencia ~ Potencia + Temperatura", donde se observa que solo necesitamos de dos variables, lo cual hace el modelo simple, pero efectivo.**

