{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":29662,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# WARNING\n**Please make sure to \"COPY AND EDIT NOTEBOOK\" to use compatible library dependencies! DO NOT CREATE A NEW NOTEBOOK AND COPY+PASTE THE CODE - this will use latest Kaggle dependencies at the time you do that, and the code will need to be modified to make it work. Also make sure internet connectivity is enabled on your notebook**","metadata":{}},{"cell_type":"markdown","source":"# Preliminaries\nFirst install critical dependencies not already on the Kaggle docker image. **NOTE THAT THIS NOTEBOOK USES TENSORFLOW 1.14 IN ORDER TO BE COMPARED WITH ELMo, WHICH WAS NOT PORTED TO TENSORFLOW 2.X. To see equivalent Tensorflow 2.X BERT Code for the Spam problem, see https://www.kaggle.com/azunre/tlfornlp-chapters2-3-spam-bert-tf2** ","metadata":{}},{"cell_type":"code","source":"!pip install keras==2.2.4 # critical dependency\n!pip install -q bert-tensorflow==1.0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:25:59.973689Z","iopub.execute_input":"2024-11-24T09:25:59.974004Z","iopub.status.idle":"2024-11-24T09:26:10.828614Z","shell.execute_reply.started":"2024-11-24T09:25:59.973936Z","shell.execute_reply":"2024-11-24T09:26:10.827798Z"}},"outputs":[{"name":"stdout","text":"Collecting keras==2.2.4\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n\u001b[K     |████████████████████████████████| 317kB 8.1MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.1.0)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.12.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (2.9.0)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.0.8)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.16.4)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (5.1.2)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.2.1)\nInstalling collected packages: keras\n  Found existing installation: Keras 2.3.0\n    Uninstalling Keras-2.3.0:\n      Successfully uninstalled Keras-2.3.0\nSuccessfully installed keras-2.2.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Write requirements to file, anytime you run it, in case you have to go back and recover Kaggle dependencies. **MOST OF THESE REQUIREMENTS WOULD NOT BE NECESSARY FOR LOCAL INSTALLATION**\n\nLatest known such requirements are hosted for each notebook in the companion github repo, and can be pulled down and installed here if needed. Companion github repo is located at https://github.com/azunre/transfer-learning-for-nlp","metadata":{}},{"cell_type":"code","source":"!pip freeze > kaggle_image_requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:10.830418Z","iopub.execute_input":"2024-11-24T09:26:10.830688Z","iopub.status.idle":"2024-11-24T09:26:13.082018Z","shell.execute_reply.started":"2024-11-24T09:26:10.830636Z","shell.execute_reply":"2024-11-24T09:26:13.081138Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Import neural network libraries\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom bert.tokenization import FullTokenizer\nfrom tensorflow.keras import backend as K\n\n# Initialize session\nsess = tf.Session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:13.083484Z","iopub.execute_input":"2024-11-24T09:26:13.083750Z","iopub.status.idle":"2024-11-24T09:26:17.296835Z","shell.execute_reply.started":"2024-11-24T09:26:13.083698Z","shell.execute_reply":"2024-11-24T09:26:17.296143Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Some other key imports\nimport os\nimport re\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:17.298195Z","iopub.execute_input":"2024-11-24T09:26:17.298410Z","iopub.status.idle":"2024-11-24T09:26:17.317353Z","shell.execute_reply.started":"2024-11-24T09:26:17.298372Z","shell.execute_reply":"2024-11-24T09:26:17.316823Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Define Tokenization, Stop-word and Punctuation Removal Functions\n\nBefore proceeding, we must decide how many samples to draw from each class. We must also decide the maximum number of tokens per email, and the maximum length of each token. This is done by setting the following overarching hyperparameters","metadata":{}},{"cell_type":"code","source":"# Params for bert model and tokenization\nNsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\nmaxtokens = 230 # the maximum number of tokens per document\nmaxtokenlen = 200 # the maximum length of each token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:17.320514Z","iopub.execute_input":"2024-11-24T09:26:17.320710Z","iopub.status.idle":"2024-11-24T09:26:17.323714Z","shell.execute_reply.started":"2024-11-24T09:26:17.320676Z","shell.execute_reply":"2024-11-24T09:26:17.323140Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Tokenization","metadata":{}},{"cell_type":"code","source":"def tokenize(row):\n    if row is None or row is '':\n        tokens = \"\"\n    else:\n        try:\n            tokens = row.split(\" \")[:maxtokens]\n        except:\n            tokens=\"\"\n    return tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:17.325450Z","iopub.execute_input":"2024-11-24T09:26:17.325640Z","iopub.status.idle":"2024-11-24T09:26:17.335616Z","shell.execute_reply.started":"2024-11-24T09:26:17.325607Z","shell.execute_reply":"2024-11-24T09:26:17.334861Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"**Use regular expressions to remove unnecessary characters**\n\nNext, we define a function to remove punctuation marks and other nonword characters (using regular expressions) from the emails with the help of the ubiquitous python regex library. In the same step, we truncate all tokens to hyperparameter maxtokenlen defined above.","metadata":{}},{"cell_type":"code","source":"def reg_expressions(row):\n    tokens = []\n    try:\n        for token in row:\n            token = token.lower()\n            token = re.sub(r'[\\W\\d]', \"\", token)\n            token = token[:maxtokenlen] # truncate token\n            tokens.append(token)\n    except:\n        token = \"\"\n        tokens.append(token)\n    return tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:17.336967Z","iopub.execute_input":"2024-11-24T09:26:17.337258Z","iopub.status.idle":"2024-11-24T09:26:17.346651Z","shell.execute_reply.started":"2024-11-24T09:26:17.337206Z","shell.execute_reply":"2024-11-24T09:26:17.346002Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"**Stop-word removal**\n\nLet’s define a function to remove stopwords - words that occur so frequently in language that they offer no useful information for classification. This includes words such as “the” and “are”, and the popular library NLTK provides a heavily-used list that will employ.","metadata":{}},{"cell_type":"code","source":"import nltk\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstopwords = stopwords.words('english')    \n\n# print(stopwords) # see default stopwords\n# it may be beneficial to drop negation words from the removal list, as they can change the positive/negative meaning\n# of a sentence - but we didn't find it to make a difference for this problem\n# stopwords.remove(\"no\")\n# stopwords.remove(\"nor\")\n# stopwords.remove(\"not\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:17.347780Z","iopub.execute_input":"2024-11-24T09:26:17.348079Z","iopub.status.idle":"2024-11-24T09:26:18.559307Z","shell.execute_reply.started":"2024-11-24T09:26:17.348028Z","shell.execute_reply":"2024-11-24T09:26:18.558392Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def stop_word_removal(row):\n    token = [token for token in row if token not in stopwords]\n    token = filter(None, token)\n    return token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:18.560903Z","iopub.execute_input":"2024-11-24T09:26:18.561239Z","iopub.status.idle":"2024-11-24T09:26:18.570616Z","shell.execute_reply.started":"2024-11-24T09:26:18.561180Z","shell.execute_reply":"2024-11-24T09:26:18.569999Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Download and Assemble IMDB Review Dataset\n\nDownload the labeled IMDB reviews","metadata":{}},{"cell_type":"code","source":"!wget -q \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n!tar xzf aclImdb_v1.tar.gz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:18.571873Z","iopub.execute_input":"2024-11-24T09:26:18.572148Z","iopub.status.idle":"2024-11-24T09:26:42.168686Z","shell.execute_reply.started":"2024-11-24T09:26:18.572101Z","shell.execute_reply":"2024-11-24T09:26:42.167589Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Shuffle and preprocess data","metadata":{}},{"cell_type":"code","source":"# function for shuffling data\ndef unison_shuffle(data, header):\n    p = np.random.permutation(len(header))\n    data = data[p]\n    header = np.asarray(header)[p]\n    return data, header\n\ndef load_data(path):\n    data, sentiments = [], []\n    for folder, sentiment in (('neg', 0), ('pos', 1)):\n        folder = os.path.join(path, folder)\n        for name in os.listdir(folder):\n            with open(os.path.join(folder, name), 'r') as reader:\n                  text = reader.read()\n            text = tokenize(text)\n            text = stop_word_removal(text)\n            text = reg_expressions(text)\n            data.append(text)\n            sentiments.append(sentiment)\n    data_np = np.array(data)\n    data, sentiments = unison_shuffle(data_np, sentiments)\n    \n    return data, sentiments\n\ntrain_path = os.path.join('aclImdb', 'train')\ntest_path = os.path.join('aclImdb', 'test')\nraw_data, raw_header = load_data(train_path)\n\nprint(raw_data.shape)\nprint(len(raw_header))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:42.170088Z","iopub.execute_input":"2024-11-24T09:26:42.170303Z","iopub.status.idle":"2024-11-24T09:26:55.359460Z","shell.execute_reply.started":"2024-11-24T09:26:42.170266Z","shell.execute_reply":"2024-11-24T09:26:55.358542Z"}},"outputs":[{"name":"stdout","text":"(25000,)\n25000\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Subsample required number of samples\nrandom_indices = np.random.choice(range(len(raw_header)),size=(Nsamp*2,),replace=False)\ndata_train = raw_data[random_indices]\nheader = raw_header[random_indices]\n\nprint(\"DEBUG::data_train::\")\nprint(data_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:55.360566Z","iopub.execute_input":"2024-11-24T09:26:55.360817Z","iopub.status.idle":"2024-11-24T09:26:55.372914Z","shell.execute_reply.started":"2024-11-24T09:26:55.360759Z","shell.execute_reply":"2024-11-24T09:26:55.372238Z"}},"outputs":[{"name":"stdout","text":"DEBUG::data_train::\n[list(['really', 'amazing', 'pile', 'pap', 'br', 'br', 'a', 'predictable', 'slow', 'moving', 'soul', 'destroying', 'mind', 'numbing', 'movie', 'which', 'slitting', 'wrists', 'rusty', 'bread', 'knife', 'seems', 'well', 'almost', 'necessarybr', 'br', 'the', 'acting', 'done', 'thin', 'dialogue', 'every', 'scene', 'least', 'twice', 'long', 'needs', 'be', 'intricate', 'details', 'career', 'collapsing', 'career', 'rising', 'far', 'dreary', 'mundane', 'words', 'the', 'music', 'would', 'good', 'sit', 'movie', 'really', 'three', 'good', 'songs', 'enough', 'reward', 'effort', 'required', 'watch', 'moviebr', 'br', 'watching', 'film', 'i', 'prayed', 'god', 'narcolepsy', 'someone', 'shoot', 'mebr', 'br', 'never', 'ever', 'ever', 'again'])\n list(['after', 'reading', 'book', 'i', 'loved', 'story', 'watching', 'movie', 'i', 'disappointed', 'many', 'changes', 'made', 'it', 'understandable', 'books', 'movies', 'differ', 'two', 'different', 'stories', 'names', 'books', 'story', 'remained', 'read', 'book', 'better', 'understanding', 'movie', 'the', 'book', 'gives', 'better', 'development', 'characters', 'these', 'characters', 'extremely', 'interesting', 'make', 'care', 'them', 'the', 'locations', 'indeed', 'line', 'books', 'descriptions', 'some', 'characters', 'included', 'television', 'microwaved', 'many', 'great', 'books', 'stories', 'perfect', 'example', 'that', 'input', 'author', 'always', 'insure', 'good', 'movie', 'help', 'sometimes'])\n list(['i', 'personally', 'watched', 'see', 'footage', 's', 's', 'it', 'fascinating', 'learn', 'drug', 'movement', 'essentially', 'started', 'became', 'pop', 'culture', 'eventual', 'uncompromising', 'force', 'life', 'the', 'interviews', 'classic', 'rock', 'stars', 'titillating', 'humorous', 'you', 'feel', 'like', 'secret', 'nodding', 'head', 'timebecause', 'feels', 'good', 'familiar', 'i', 'loved', 'it', 'segments', 'spresent', 'day', 'i', 'highly', 'recommend', 'aspects', 'including', 'rock', 'music', 'hipper', 'movement', 'politics', 'good', 'ol', 'history', 'i', 'check', 'marked', 'box', 'saying', 'contains', 'spoiler', 'i', 'idea', 'might', 'consider', 'spoiler', 'regards', 'since', 'i', 'discussed', 'whats', '', 'segments', 'wanted', 'safe'])\n ...\n list(['ive', 'seen', 'lot', 'tv', 'movies', 'time', 'student', 'majority', 'normal', 'waste', 'time', 'us', 'television', 'throws', 'out', 'this', 'one', 'however', 'well', 'crafted', 'plotted', 'nice', 'twist', 'end', 'having', 'seen', 'richard', 'dean', 'anderson', 'macgyver', 'stargate', 'i', 'surprised', 'excellent', 'performance', 'rather', 'rather', 'gamut', 'expressions', 'ab', 'normally', 'gives', 'it', 'pleasant', 'surprise', 'see', 'daphne', 'zuniga', 'quite', 'long', 'time', 'dating', 'back', 'the', 'fly', 'ii', 'also', 'nice', 'see', 'robert', 'guillaumme', 'leading', 'role', 'again', 'i', 'cant', 'say', 'i', 'ever', 'take', 'jane', 'leeves', 'seriously', 'benny', 'hill', 'days', 'managed', 'cope', 'well', 'role', 'all', 'highly', 'recommended', 'film'])\n list(['when', 'the', 'magic', 'of', 'lassie', 'opened', 'radio', 'city', 'music', 'hall', 'i', 'foolish', 'enough', 'believe', 'would', 'heartwarming', 'first', 'lassie', 'films', 'were', 'notbr', 'br', 'the', 'story', 'abysmal', 'songs', 'sherman', 'brothers', 'way', 'usual', 'level', 'characters', 'uninspired', 'james', 'stewart', 'mickey', 'rooney', 'seen', 'much', 'better', 'daysbr', 'br', 'then', 'too', 'i', 'interested', 'seeing', 'alice', 'fayes', 'contribution', 'would', 'like', 'since', 'shed', 'absent', 'screen', 'many', 'years', 'always', 'fetching', 'earlier', 'roles', 'fox', 'alice', 'too', 'letdown', 'foolish', 'script', 'unflattering', 'photography', 'another', 'disappointmentbr', 'br', 'nothing', 'original', 'here', 'nothing', 'even', 'remotely', 'interesting', 'adult', 'enjoyand', 'clearly', 'magic', 'present', 'anyone', 'you', 'skip', 'one', 'without', 'missing', 'thing'])\n list(['great', 'movie', '', 'especially', 'music', '', 'etta', 'james', '', 'at', 'last', 'this', 'speaks', 'volumes', 'finally', 'found', 'special', 'someone'])]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Display sentiments and their frequencies in the dataset, to ensure it is roughly balanced between classes","metadata":{}},{"cell_type":"code","source":"unique_elements, counts_elements = np.unique(header, return_counts=True)\nprint(\"Sentiments and their frequencies:\")\nprint(unique_elements)\nprint(counts_elements)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:55.374081Z","iopub.execute_input":"2024-11-24T09:26:55.374346Z","iopub.status.idle":"2024-11-24T09:26:55.384603Z","shell.execute_reply.started":"2024-11-24T09:26:55.374294Z","shell.execute_reply":"2024-11-24T09:26:55.383893Z"}},"outputs":[{"name":"stdout","text":"Sentiments and their frequencies:\n[0 1]\n[1003  997]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# function for converting data into the right format, due to the difference in required format from sklearn models\n# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\ndef convert_data(raw_data,header):\n    converted_data, labels = [], []\n    for i in range(raw_data.shape[0]):\n        # combine list of tokens representing each email into single string\n        out = ' '.join(raw_data[i])\n        converted_data.append(out)\n        labels.append(header[i])\n    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n    \n    return converted_data, np.array(labels)\n\ndata_train, header = unison_shuffle(data_train, header)\n\n# split into independent 70% training and 30% testing sets\nidx = int(0.7*data_train.shape[0])\n# 70% of data for training\ntrain_x, train_y = convert_data(data_train[:idx],header[:idx])\n# remaining 30% for testing\ntest_x, test_y = convert_data(data_train[idx:],header[idx:])\n\nprint(\"train_x/train_y list details, to make sure it is of the right form:\")\nprint(len(train_x))\nprint(train_x)\nprint(train_y[:5])\nprint(train_y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:55.385754Z","iopub.execute_input":"2024-11-24T09:26:55.386056Z","iopub.status.idle":"2024-11-24T09:26:55.404959Z","shell.execute_reply.started":"2024-11-24T09:26:55.386000Z","shell.execute_reply":"2024-11-24T09:26:55.404283Z"}},"outputs":[{"name":"stdout","text":"train_x/train_y list details, to make sure it is of the right form:\n1400\n[['a series shorts spoofing dumb tv shows groove tube hits misses lot overall i really like movie unfortunately couple segments totally boring a really great clips make this a predecessor classics like kentucky fried movie']\n ['damon runyons world times square new york prior disneyfication basis musical joseph l mankiewicz man knew movies directed nostalgic tribute crossroads world show us underside new york past frank loessers music sounds great we watch magnificent cast characters typical area people edges society tended gravitate toward area lights action possibilities part town this underbelly city made living street life intensebr br some songs original production included film we know whether makes sense unusual hollywood musical change alter worked stage that original cast included wonderful vivian blaine stubby kaye wonder decision letting robert alda sam levene isabel bigley repeat original roles these distinguished actors could made amazing contributionbr br the film visually amazing the look follows closely fashions times as far casting marlon brando otherwise known singing abilities frank sinatra jean simmons seem work']\n ['this gorgeous movie visually the images mexican desert old mansion characters picturesque costumesall amount real work artbr br the story seems bit loose thats meant realistic it taken book called one hundred years solitude supposed evocation isolated otherworldly atmosphere latin america so far god close united states the tremendous debt erendira owes grandmother symbolic latin americas international debt burden although many layers meaningbr br if appreciate slowmoving richlytextured movie one you']\n ...\n ['michael kallio gives strong convincing performance eric seaver troubled young man horribly mistreated little boy monstrous abusive alcoholic stepfather barry a genuinely frightening portrayal gunnar hansen eric compassionate fiancé sweetly played lovely tracee newberry job transcribing autopsy reports local morgue haunted bleak past egged bald beaming jack demon a truly creepy michael robert brandon sent edge recent death mother eric goes deep end embarks brutal killing spree capably directed kallio who also wrote tight astute script uniformly fine acting sound noname cast jeff steiger especially good erics wannabe helpful guardian angel michael rather rough overall polished cinematography george lieber believable truetolife characters jolting outbursts raw shocking unflinchingly ferocious violence moody spooky score dan kolton uncompromisingly downbeat ending grungy detroit michigan locations grimly serious tone taut gripping narrative stays steady track throughout extremely potent gritty psychological horror thriller makes often absorbing disturbing viewing a real sleeper']\n ['genie zoe trilling arrives egypt visit hypocritical biblequoting archeologist father william finley attracts attention group cultists led descendant marquis de sade robert englund englund also plays de sade flashbacks ranting cell genie led astray mohammed juliano merr rides around naked horse sabina alona kamhi bisexual introduces opium smoking leads wild hallucination featuring topless harem dancers woman simulating oral sex snake orgy father preaching background meanwhile black hooded cult members decapitate gouge eyeballs slit throats when genie slipped drugs tea imagines de sade hanging cross goldpainted woman leafy gstring bloody bed covered snakes its reincarnation de sades lost lovebr br this typically sleazy harry alan towers production redundant seedy pretty senseless sets costumes cinematography location work excellent least theres always something going onbr br score  ']\n ['its spelled slashers i happy main character flashed boobs that pretty tight before movie pretty much blows the acting like elist shown well movie not mention low budget preacherman chainsaw charlie played person the whole movie looks like shot camcorder instead half way decent film the reason i liked movie chainsaw charlie doctor ripper funny they said many stupid things made laugh other see movie blockbuster everyone favor hide behind lawnmowerman  anybody thinks movie good mentally evaluated']]\n[1 1 1 1 1]\n(1400,)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Build, Train and Evaluate BERT Model\nFirst define critical functions that define various components of the BERT model","metadata":{}},{"cell_type":"code","source":"class InputExample(object):\n    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n\n    def __init__(self, guid, text_a, text_b=None, label=None):\n        \"\"\"Constructs a InputExample.\n    Args:\n      guid: Unique id for the example.\n      text_a: string. The untokenized text of the first sequence. For single\n        sequence tasks, only this sequence must be specified.\n      text_b: (Optional) string. The untokenized text of the second sequence.\n        Only must be specified for sequence pair tasks.\n      label: (Optional) string. The label of the example. This should be\n        specified for train examples, but not for test examples.\n    \"\"\"\n        self.guid = guid\n        self.text_a = text_a\n        self.text_b = text_b\n        self.label = label\n\n\ndef create_tokenizer_from_hub_module(bert_path):\n    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n    bert_module = hub.Module(bert_path)\n    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n    vocab_file, do_lower_case = sess.run(\n        [tokenization_info[\"vocab_file\"], tokenization_info[\"do_lower_case\"]]\n    )\n\n    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n\n\ndef convert_single_example(tokenizer, example, max_seq_length=256):\n    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n\n    tokens_a = tokenizer.tokenize(example.text_a)\n    if len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n\n    tokens = []\n    segment_ids = []\n    tokens.append(\"[CLS]\")\n    segment_ids.append(0)\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(0)\n    tokens.append(\"[SEP]\")\n    segment_ids.append(0)\n\n    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n\n    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n    # tokens are attended to.\n    input_mask = [1] * len(input_ids)\n\n    # Zero-pad up to the sequence length.\n    while len(input_ids) < max_seq_length:\n        input_ids.append(0)\n        input_mask.append(0)\n        segment_ids.append(0)\n\n    assert len(input_ids) == max_seq_length\n    assert len(input_mask) == max_seq_length\n    assert len(segment_ids) == max_seq_length\n\n    return input_ids, input_mask, segment_ids, example.label\n\n\ndef convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n\n    input_ids, input_masks, segment_ids, labels = [], [], [], []\n    for example in tqdm(examples, desc=\"Converting examples to features\"):\n        input_id, input_mask, segment_id, label = convert_single_example(\n            tokenizer, example, max_seq_length\n        )\n        input_ids.append(input_id)\n        input_masks.append(input_mask)\n        segment_ids.append(segment_id)\n        labels.append(label)\n    return (\n        np.array(input_ids),\n        np.array(input_masks),\n        np.array(segment_ids),\n        np.array(labels).reshape(-1, 1),\n    )\n\n\ndef convert_text_to_examples(texts, labels):\n    \"\"\"Create InputExamples\"\"\"\n    InputExamples = []\n    for text, label in zip(texts, labels):\n        InputExamples.append(\n            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n        )\n    return InputExamples","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:55.406231Z","iopub.execute_input":"2024-11-24T09:26:55.406609Z","iopub.status.idle":"2024-11-24T09:26:55.421875Z","shell.execute_reply.started":"2024-11-24T09:26:55.406444Z","shell.execute_reply":"2024-11-24T09:26:55.421149Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"Next, we define a custom tf hub BERT layer","metadata":{}},{"cell_type":"code","source":"class BertLayer(tf.keras.layers.Layer):\n    def __init__(\n        self,\n        n_fine_tune_layers=10,\n        pooling=\"mean\",\n        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n        **kwargs,\n    ):\n        self.n_fine_tune_layers = n_fine_tune_layers\n        self.trainable = True\n        self.output_size = 768\n        self.pooling = pooling\n        self.bert_path = bert_path\n        if self.pooling not in [\"first\", \"mean\"]:\n            raise NameError(\n                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n            )\n\n        super(BertLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.bert = hub.Module(\n            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n        )\n\n        # Remove unused layers\n        trainable_vars = self.bert.variables\n        if self.pooling == \"first\":\n            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n            trainable_layers = [\"pooler/dense\"]\n\n        elif self.pooling == \"mean\":\n            trainable_vars = [\n                var\n                for var in trainable_vars\n                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n            ]\n            trainable_layers = []\n        else:\n            raise NameError(\n                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n            )\n\n        # Select how many layers to fine tune\n        for i in range(self.n_fine_tune_layers):\n            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n\n        # Update trainable vars to contain only the specified layers\n        trainable_vars = [\n            var\n            for var in trainable_vars\n            if any([l in var.name for l in trainable_layers])\n        ]\n\n        # Add to trainable weights\n        for var in trainable_vars:\n            self._trainable_weights.append(var)\n\n        for var in self.bert.variables:\n            if var not in self._trainable_weights:\n                self._non_trainable_weights.append(var)\n\n        super(BertLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n        input_ids, input_mask, segment_ids = inputs\n        bert_inputs = dict(\n            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n        )\n        if self.pooling == \"first\":\n            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n                \"pooled_output\"\n            ]\n        elif self.pooling == \"mean\":\n            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n                \"sequence_output\"\n            ]\n\n            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n            input_mask = tf.cast(input_mask, tf.float32)\n            pooled = masked_reduce_mean(result, input_mask)\n        else:\n            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n\n        return pooled\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.output_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:55.423288Z","iopub.execute_input":"2024-11-24T09:26:55.423580Z","iopub.status.idle":"2024-11-24T09:26:55.440465Z","shell.execute_reply.started":"2024-11-24T09:26:55.423528Z","shell.execute_reply":"2024-11-24T09:26:55.439536Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"We now use the custom TF hub BERT embedding layer within a higher-level function to define the overall model. More specifically, we put a dense trainable layer of output dimension 256 on top of the BERT embedding.","metadata":{}},{"cell_type":"code","source":"# Function to build overall model\ndef build_model(max_seq_length):\n    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n    bert_inputs = [in_id, in_mask, in_segment]\n    \n    # just extract BERT features, don't fine-tune\n    bert_output = BertLayer(n_fine_tune_layers=0)(bert_inputs)\n    # train dense classification layer on top of extracted features\n    dense = tf.keras.layers.Dense(256, activation=\"relu\")(bert_output)\n    pred = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dense)\n\n    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    model.summary()\n\n    return model\n\n# Function to initialize variables correctly\ndef initialize_vars(sess):\n    sess.run(tf.local_variables_initializer())\n    sess.run(tf.global_variables_initializer())\n    sess.run(tf.tables_initializer())\n    K.set_session(sess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:55.441437Z","iopub.execute_input":"2024-11-24T09:26:55.441753Z","iopub.status.idle":"2024-11-24T09:26:55.454353Z","shell.execute_reply.started":"2024-11-24T09:26:55.441703Z","shell.execute_reply":"2024-11-24T09:26:55.453740Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# tf hub bert model path\nbert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" \n\n# Instantiate tokenizer\ntokenizer = create_tokenizer_from_hub_module(bert_path)\n\n# Convert data to InputExample format\ntrain_examples = convert_text_to_examples(train_x, train_y)\ntest_examples = convert_text_to_examples(test_x, test_y)\n\n# Convert to features\n(train_input_ids,train_input_masks,train_segment_ids,train_labels) = \\\nconvert_examples_to_features(tokenizer, train_examples, max_seq_length=maxtokens)\n(test_input_ids,test_input_masks,test_segment_ids,test_labels) = \\\nconvert_examples_to_features(tokenizer, test_examples, max_seq_length=maxtokens)\n\n# Build model\nmodel = build_model(maxtokens)\n\n# Instantiate variables\ninitialize_vars(sess)\n\n# Train model\nhistory = model.fit([train_input_ids, train_input_masks, train_segment_ids],train_labels,\n                    validation_data=([test_input_ids, test_input_masks, test_segment_ids],test_labels),\n                    epochs=5,batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:26:55.455524Z","iopub.execute_input":"2024-11-24T09:26:55.455803Z","iopub.status.idle":"2024-11-24T09:29:07.359070Z","shell.execute_reply.started":"2024-11-24T09:26:55.455753Z","shell.execute_reply":"2024-11-24T09:29:07.358298Z"}},"outputs":[{"name":"stderr","text":"Converting examples to features: 100%|██████████| 1400/1400 [00:02<00:00, 491.41it/s]\nConverting examples to features: 100%|██████████| 600/600 [00:01<00:00, 504.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"WARNING: Entity <bound method BertLayer.call of <__main__.BertLayer object at 0x7bf1e15645f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertLayer.call of <__main__.BertLayer object at 0x7bf1e15645f8>>: AttributeError: module 'gast' has no attribute 'Num'\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_ids (InputLayer)          [(None, 230)]        0                                            \n__________________________________________________________________________________________________\ninput_masks (InputLayer)        [(None, 230)]        0                                            \n__________________________________________________________________________________________________\nsegment_ids (InputLayer)        [(None, 230)]        0                                            \n__________________________________________________________________________________________________\nbert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n                                                                 input_masks[0][0]                \n                                                                 segment_ids[0][0]                \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n==================================================================================================\nTotal params: 110,302,011\nTrainable params: 197,121\nNon-trainable params: 110,104,890\n__________________________________________________________________________________________________\nTrain on 1400 samples, validate on 600 samples\nEpoch 1/5\n1400/1400 [==============================] - 20s 14ms/sample - loss: 0.5573 - acc: 0.7014 - val_loss: 0.4451 - val_acc: 0.8133\nEpoch 2/5\n1400/1400 [==============================] - 18s 13ms/sample - loss: 0.4715 - acc: 0.7736 - val_loss: 0.5096 - val_acc: 0.7367\nEpoch 3/5\n1400/1400 [==============================] - 18s 13ms/sample - loss: 0.4406 - acc: 0.7950 - val_loss: 0.4016 - val_acc: 0.8150\nEpoch 4/5\n1400/1400 [==============================] - 18s 13ms/sample - loss: 0.4205 - acc: 0.8107 - val_loss: 0.4130 - val_acc: 0.8150\nEpoch 5/5\n1400/1400 [==============================] - 18s 13ms/sample - loss: 0.3901 - acc: 0.8271 - val_loss: 0.3938 - val_acc: 0.8200\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**Visualize Convergence**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf_history = pd.DataFrame(history.history)\nfig,ax = plt.subplots()\nplt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\nplt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('BERT Email Classification Training')\nplt.legend(loc='best')\nplt.grid()\nplt.show()\n\nfig.savefig('BERTConvergence.eps', format='eps')\nfig.savefig('BERTConvergence.pdf', format='pdf')\nfig.savefig('BERTConvergence.png', format='png')\nfig.savefig('BERTConvergence.svg', format='svg')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:29:07.360697Z","iopub.execute_input":"2024-11-24T09:29:07.361044Z","iopub.status.idle":"2024-11-24T09:29:07.739427Z","shell.execute_reply.started":"2024-11-24T09:29:07.360985Z","shell.execute_reply":"2024-11-24T09:29:07.738785Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}],"execution_count":19},{"cell_type":"markdown","source":"**Make figures downloadable to local system in interactive mode**","metadata":{}},{"cell_type":"code","source":"from IPython.display import HTML\ndef create_download_link(title = \"Download file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(filename='BERTConvergence.svg')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:29:07.740391Z","iopub.execute_input":"2024-11-24T09:29:07.740630Z","iopub.status.idle":"2024-11-24T09:29:07.745856Z","shell.execute_reply.started":"2024-11-24T09:29:07.740583Z","shell.execute_reply":"2024-11-24T09:29:07.745199Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a href=BERTConvergence.svg>Download file</a>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"!ls\n!rm -rf aclImdb\n!rm aclImdb_v1.tar.gz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:29:07.747210Z","iopub.execute_input":"2024-11-24T09:29:07.747437Z","iopub.status.idle":"2024-11-24T09:29:12.886128Z","shell.execute_reply.started":"2024-11-24T09:29:07.747391Z","shell.execute_reply":"2024-11-24T09:29:12.885255Z"}},"outputs":[{"name":"stdout","text":"BERTConvergence.eps  BERTConvergence.svg  kaggle_image_requirements.txt\nBERTConvergence.pdf  aclImdb\nBERTConvergence.png  aclImdb_v1.tar.gz\n","output_type":"stream"}],"execution_count":21}]}